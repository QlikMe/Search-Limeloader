{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from IPython.core.display import HTML\n",
    "import logging\n",
    "m_logger = None\n",
    "\n",
    "def initLogger(msg=\"Started!\", level=logging.DEBUG):\n",
    "    \"Limeloader Logging system\"\n",
    "    global m_logger\n",
    "    m_logger = logging.getLogger(__name__)\n",
    "    handler = logging.StreamHandler(sys.stderr)\n",
    "    m_logger.handlers = []\n",
    "    m_logger.addHandler(handler)\n",
    "    m_logger.setLevel(level)\n",
    "    m_logger.debug(msg)\n",
    "    \n",
    "initLogger(\"Limeloader 0.1\")\n",
    "\n",
    "page = open(\"data/usage.html\", \"r\")\n",
    "contents = page.read()\n",
    "HTML(contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## LOAD CSV in Dictionary list\n",
    "## Set options in m_options at bottom of cell\n",
    "\n",
    "import requests\n",
    "\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import csv\n",
    "import json\n",
    "import codecs\n",
    "import time, datetime\n",
    "import getpass, sys\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "\n",
    "m_version = \"1.0.0\"\n",
    "\n",
    "m_dataFile = \"\"\n",
    "m_data = []\n",
    "m_defaultHost = 'localhost'\n",
    "\n",
    "\n",
    "m_columnNames = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def loadData(file, display=False):\n",
    "    \"Load CSV data into m_data\"\n",
    "    global m_data, m_dataFile\n",
    "    m_dataFile = file\n",
    "    m_data = loadListFromCSV(m_dataFile, display)\n",
    "    \n",
    "\n",
    "def loadListFromCSV(path, display=False):\n",
    "    \"Load unicode CSV file\"\n",
    "    header = [];\n",
    "    dList = []\n",
    "    \n",
    "    with open(path) as f:\n",
    "        headerNeeded = True\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if headerNeeded:\n",
    "                idx = 0\n",
    "                for col in row:\n",
    "                    header.append(col)\n",
    "                    idx += 1\n",
    "                headerNeeded = False\n",
    "                m_logger.debug(\"loadListFromCSV: Header with \"+str(idx)+\" columns read from file: \"+path)\n",
    "            else:\n",
    "                data = []\n",
    "                idx = 0\n",
    "                for value in row:\n",
    "                    item = {}\n",
    "                    column = header[idx] \n",
    "                    item[\"name\"] = column\n",
    "                    item[\"value\"] = value\n",
    "                    dataType = \"attribute\"\n",
    "                    if column[:1] == '_':\n",
    "                        dataType = \"dimension\"\n",
    "                    elif column.isupper():\n",
    "                        dataType = \"measure\"\n",
    "                    item[\"dataType\"] = dataType\n",
    "                    data.append(item);\n",
    "\n",
    "                    idx += 1\n",
    "                    \n",
    "                dList.append(data)\n",
    "    \n",
    "    m_logger.debug(\"loadListFromCSV: \"+str(len(dList))+\" data records read from file: \"+path)\n",
    "    \n",
    "    if display:\n",
    "#        print (\"Columns:\")\n",
    "#        print (header)\n",
    "        idx = 1\n",
    "        for row in dList:\n",
    "            print (\"Row \"+str(idx)+\":\")\n",
    "            print (row)\n",
    "            idx = idx +1\n",
    "            \n",
    "    return dList\n",
    "    \n",
    "\n",
    "def dictItemToCSV(item, columnNames, zeroFill=False, extra={}):\n",
    "    \"Dict item to CSV conversion\"\n",
    "    line = []\n",
    "    source = item[\"_source\"] if (\"_source\" in item) else {}\n",
    "    for name in columnNames:\n",
    "        if name in extra:\n",
    "            line.append(extra[name])\n",
    "        elif name in source:\n",
    "            line.append(source[name])\n",
    "        elif name in item:\n",
    "            line.append(item[name])\n",
    "        elif zeroFill:\n",
    "            line.append(\"0\")\n",
    "        else:\n",
    "            line.append(\"\")\n",
    "\n",
    "    return line\n",
    "\n",
    "def writeListToCSV(basename, dlist, columnNames, display=False):\n",
    "    \"Write Unicode CSV file\"\n",
    "    fileName = \"./output/actions-\"+basename+\".csv\"\n",
    "    m_logger.debug(\"writeResultsToCSV: Saving \"+str(len(dlist))+\" records to file: \"+fileName)\n",
    "\n",
    "    with open(fileName, 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(columnNames)\n",
    "        for item in dlist:\n",
    "            csvItem = dictItemToCSV(item,columnNames)\n",
    "            if display:\n",
    "                print (item)\n",
    "            writer.writerow(csvItem)\n",
    "\n",
    "def writeHeaderToCSV(basename, columnNames, display=False):\n",
    "    \"Write Unicode CSV file\"\n",
    "    fileName = \"./output/actions-\"+basename+\".csv\"\n",
    "    m_logger.debug(\"writeResultsToCSV: Writing to file: \"+fileName)\n",
    "\n",
    "    if display:\n",
    "        print (columnNames)\n",
    "\n",
    "    with open(fileName, 'w') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(columnNames)\n",
    "\n",
    "\n",
    "def appendListToCSV(basename, dList, columnNames, zeroFill=False, display=False):\n",
    "    \"Append data to Unicode CSV file\"\n",
    "    fileName = \"./output/actions-\"+basename+\".csv\"\n",
    "    m_logger.debug(\"appendListToCSV: Appending \"+str(len(dList))+\" records to file: \"+fileName)\n",
    "\n",
    "    with open(fileName, 'a') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for item in dList:\n",
    "            csvItem = dictItemToCSV(item,columnNames,zeroFill)\n",
    "            if display:\n",
    "                print (item)\n",
    "            writer.writerow(csvItem)\n",
    "        \n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "def initialize(msg):\n",
    "    \"Initialize\"\n",
    "    initLogger(msg)\n",
    "\n",
    "\n",
    "# **** START HERE ******\n",
    "m_options = {\n",
    "    \"file\": \"data/BigSet.csv\", # Incoming data\n",
    "    \"es\": \"http://localhost:9200\", # Target ES host:port\n",
    "    \"indexName\": \"qlik/document\", # Target ES index\n",
    "    \"trace\": True, # Target ES host, Required\n",
    "    \"query\": \"ikea\"\n",
    "}\n",
    "\n",
    "m_logger.debug(\"** Options **\")\n",
    "m_logger.debug(m_options)\n",
    "\n",
    "loadData(m_options[\"file\"],True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## DELETE Qlik INDEX - R U SURE????\n",
    "## Remember to start Elastic Search server at address specified in m_options (usually localhost:9200)\n",
    "import requests\n",
    "url = 'http://localhost:9200/qlik/'\n",
    "response = requests.delete(url)\n",
    "jsonData = response.json()\n",
    "print (jsonData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Write Dictionary list to Elastic Search\n",
    "## Remember to start Elastic Search server at address specified in m_options (usually localhost:9200)\n",
    "\n",
    "import requests\n",
    "\n",
    "def writeToIndex(indexItem):\n",
    "    data = json.dumps(indexItem)\n",
    "    print (\"writeToIndex:\")\n",
    "    print (data)\n",
    "\n",
    "    url = 'http://localhost:9200/qlik/document/'\n",
    "    response = requests.post(url, data=data)\n",
    "    jsonData = response.json()\n",
    "    print (jsonData)\n",
    "    \n",
    "def addRowToIndex(attributes, measures, dimensions, display=False):\n",
    "    \"Add row to Elastic Search index\"\n",
    "    \n",
    "    for measure in measures:\n",
    "        indexItem = {}\n",
    "        for attribute in attributes:\n",
    "            indexItem[attribute[\"name\"]] = attribute[\"value\"]\n",
    "        for dimension in dimensions:\n",
    "            indexItem[dimension[\"name\"]] = dimension[\"value\"]\n",
    "        indexItem[\"name\"] = measure[\"name\"]\n",
    "        indexItem[\"value\"] = measure[\"value\"]\n",
    "        writeToIndex(indexItem)\n",
    "\n",
    "def writeListToIndex(dList, url, display=False):\n",
    "    \"Write dictonary list to Elastic Search\"\n",
    "\n",
    "    \n",
    "    idx = 1\n",
    "    for row in dList:\n",
    "        attributes = []\n",
    "        measures = []\n",
    "        dimensions = []\n",
    "        for item in row:\n",
    "            if item[\"dataType\"] == \"attribute\":\n",
    "                attributes.append(item)\n",
    "            elif item[\"dataType\"] == \"measure\":\n",
    "                measures.append(item)\n",
    "            elif item[\"dataType\"] == \"dimension\":\n",
    "                dimensions.append(item)\n",
    "                \n",
    "        if display:\n",
    "            print (\"Row \"+str(idx)+\":\")\n",
    "#            print (attributes)\n",
    "#            print (measures)\n",
    "#            print (dimensions)\n",
    "        \n",
    "        addRowToIndex(attributes,measures,dimensions,display)\n",
    "        idx += 1\n",
    "    return dList\n",
    "    \n",
    "\n",
    "writeListToIndex(m_data, m_options[\"file\"], m_options[\"trace\"]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Get ES Stats and content\n",
    "\n",
    "import requests\n",
    "\n",
    "response = requests.get('http://localhost:9200/qlik/?format=json&pretty')\n",
    "jsonData = response.json()\n",
    "print (jsonData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Simple Field Search\n",
    "\n",
    "import requests\n",
    "url = 'http://localhost:9200/qlik/document/'\n",
    "data = \"\"\"{\n",
    "    \"name\": \"ikea\",\n",
    "    \"Country\": \"Sweden\",\n",
    "    \"Private\": \"True\"\n",
    "}\"\"\"\n",
    "response = requests.post(url, data=data)\n",
    "jsonData = response.json()\n",
    "print (jsonData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Another Field Search\n",
    "\n",
    "import requests\n",
    "url = 'http://localhost:9200/qlik/document/'\n",
    "data = \"\"\"{\n",
    "    \"test1\": \"1111\",\n",
    "    \"test2\": \"2222\",\n",
    "    \"test3\": \"3333\"\n",
    "}\"\"\"\n",
    "response = requests.post(url, data=data)\n",
    "jsonData = response.json()\n",
    "print (jsonData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Single Term Search\n",
    "\n",
    "import requests\n",
    "url = 'http://localhost:9200/qlik/_search?format=json&pretty=true'\n",
    "data = \"\"\"{\n",
    "    \"query\": {\n",
    "        \"term\": {\"Country\":\"sweden\"}\n",
    "    }\n",
    "}\"\"\"\n",
    "response = requests.post(url, data=data)\n",
    "jsonData = response.json()\n",
    "print (jsonData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'http://localhost:9200/qlik/_search?format=json&pretty=true'\n",
    "data = \"\"\"{\n",
    "  \"query\": {\n",
    "    \"multi_match\" : {\n",
    "      \"query\":    \"ikea\", \n",
    "      \"fields\": [ \"n*\" ] \n",
    "    }\n",
    "  }\n",
    "}\"\"\"\n",
    "response = requests.post(url, data=data)\n",
    "jsonData = response.json()\n",
    "print (jsonData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get Index schema\n",
    "\n",
    "import requests\n",
    "url = 'http://localhost:9200/qlik/document/_mapping'\n",
    "response = requests.get(url)\n",
    "jsonData = response.json()\n",
    "print (jsonData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
